{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта\n",
    "\n",
    "Допустим, вы работаете в добывающей компании «ГлавРосГосНефть». Нужно решить, где бурить новую скважину.\n",
    "\n",
    "Вам предоставлены пробы нефти в трёх регионах: в каждом 10 000 месторождений, где измерили качество нефти и объём её запасов. Постройте модель машинного обучения, которая поможет определить регион, где добыча принесёт наибольшую прибыль. Проанализируйте возможную прибыль и риски техникой *Bootstrap.*\n",
    "\n",
    "Шаги для выбора локации:\n",
    "\n",
    "- В избранном регионе ищут месторождения, для каждого определяют значения признаков;\n",
    "\n",
    "- Строят модель и оценивают объём запасов;\n",
    "\n",
    "- Выбирают месторождения с самым высокими оценками значений. Количество месторождений зависит от бюджета компании и стоимости разработки одной скважины;\n",
    "\n",
    "- Определяют регион с максимальной суммарной прибылью отобранных скважин (прибыль равна суммарной прибыли отобранных месторождений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание данных\n",
    "\n",
    "Данные геологоразведки трёх регионов находятся в соответствующих файлах. \n",
    "\n",
    "- `id` — уникальный идентификатор скважины;\n",
    "\n",
    "- `f0`, `f1`, `f2` — три признака точек (неважно, что они означают, но сами признаки значимы);\n",
    "\n",
    "- `product` — объём запасов в скважине (тыс. баррелей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Условия задачи\n",
    "\n",
    "- Для обучения модели подходит только линейная регрессия (остальные — недостаточно предсказуемые).\n",
    "\n",
    "- При разведке региона исследуют 500 точек, из которых с помощью машинного обучения выбирают 200 лучших для разработки.\n",
    "\n",
    "- Бюджет на разработку скважин в регионе — 10 млрд рублей.\n",
    "\n",
    "- При нынешних ценах один баррель сырья приносит 450 рублей дохода. Доход с каждой единицы продукта составляет 450 тыс. рублей, поскольку объём указан в тысячах баррелей.\n",
    "\n",
    "- После оценки рисков нужно оставить лишь те регионы, в которых вероятность убытков меньше 2.5%. Среди них выбирают регион с наибольшей средней прибылью.\n",
    "\n",
    "Данные синтетические: детали контрактов и характеристики месторождений не разглашаются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение библиотек\n",
    "\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression # линейная регрессия\n",
    "from sklearn.dummy import DummyRegressor # для проверки модели на адекватность\n",
    "\n",
    "from sklearn.model_selection import train_test_split # для разделения выборки\n",
    "from sklearn.preprocessing import StandardScaler # для масштабирования признаков\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error # метрики\n",
    "\n",
    "# Настройки\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Константы\n",
    "\n",
    "STATE = 123 # значение для параметра random_state\n",
    "\n",
    "BUDGET = 10 * (10 ** 9) # бюджет на разработку скважин в регионе, руб.\n",
    "UNIT_INCOME = 450000 # доход с каждой единицы продукта, руб.\n",
    "NUM_WELLS = 200 # требуемое кол-во точек для разработки, шт.\n",
    "\n",
    "N_SAMP = 1000 # кол-во выборок для техники Bootstrap\n",
    "N = 500 # кол-во точек при разведке региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для формирования информационных отчетов по каждому региону\n",
    "\n",
    "def inform_report(list_df):\n",
    "    list_reports = []\n",
    "    list_names = []\n",
    "    \n",
    "    for num in range(len(list_df)):\n",
    "        \n",
    "        title = 'Geo_data_' + str(num)\n",
    "        report = sv.analyze([list_df[num], title])\n",
    "        report_name = 'Common_analysis_' + str(num) + '.html'\n",
    "        \n",
    "        list_reports.append(report)\n",
    "        list_names.append(report_name)\n",
    "    \n",
    "    return dict(zip(list_names, list_reports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для стандартизации признаков\n",
    "\n",
    "def scaler_features(features_train, features_valid):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(features_train)\n",
    "    \n",
    "    features_train = scaler.transform(features_train)\n",
    "    features_valid = scaler.transform(features_valid)\n",
    "    \n",
    "    return features_train, features_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для построения модели (для каждого региона)\n",
    "\n",
    "def lr_model(features_train, features_valid, target_train, target_valid):\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(features_train, target_train)\n",
    "    \n",
    "    target_pred = lr.predict(features_valid)\n",
    "    score = mean_squared_error(target_valid, target_pred) ** 0.5\n",
    "    \n",
    "    return lr_model, target_pred, score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для построения модели DummyRegressor (для проверки моделей на адекватность)\n",
    "\n",
    "def dr_model(features_train, features_valid, target_train, target_valid, value, strategy='constant'):\n",
    "    \n",
    "    dr = DummyRegressor(strategy=strategy, constant=value)\n",
    "    dr.fit(features_train, target_train)\n",
    "    \n",
    "    score = mean_squared_error(target_valid, dr.predict(features_valid)) ** 0.5\n",
    "    \n",
    "    return score   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_0 = pd.read_csv('geo_data_0.csv')\n",
    "    df_1 = pd.read_csv('geo_data_1.csv')\n",
    "    df_2 = pd.read_csv('geo_data_2.csv')\n",
    "except:\n",
    "    df_0 = pd.read_csv('https://code.s3.yandex.net/datasets/geo_data_0.csv')\n",
    "    df_1 = pd.read_csv('https://code.s3.yandex.net/datasets/geo_data_1.csv')\n",
    "    df_2 = pd.read_csv('https://code.s3.yandex.net/datasets/geo_data_2.csv')\n",
    "    \n",
    "df_list = [df_0, df_1, df_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b13e204b72146b2969478af592e3f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32687b5408c6417ca9ff43a77f8fd84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d84afdced2f14cb888a4f88fd2faddd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report Common_analysis_0.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "Report Common_analysis_1.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n",
      "Report Common_analysis_2.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "# Формируем отчёты по каждому региону\n",
    "\n",
    "for key, value in inform_report(df_list).items():\n",
    "    value.show_html(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проанализировав отчёты можно сказать следующее:\n",
    "\n",
    "Количество строк и столбцов каждого датафрейма: 100_000 и 5, соответственно. Все признаки, за исключением признака `id`, являются численными. Пропусков и полных дубликатов ни в одном датафрейме нет. Однако, в признаке `id` наблюдается небольшой процент дубликатов (менее 1%) — далее удалим соотв. строки, каждый раз оставляя последнюю запись (возможно есть привязка к дате сбора информации и последняя запись самая актуальная).\n",
    "\n",
    "Также, по двум регионам наблюдается небольшой процент скважин с нулевым значение в признаке `product` — удалим соответствующие записи, по одному региону этот процент выше (около 8%), однако, в сравнении с размером датафрейма есть основания полагать данный набор записей незначительным, также удалим такие записи. \n",
    "\n",
    "Мультиколлинеарности признаков не обнаружено. Однако, стоит отметить, что для каждого региона, признак `f2` наиболее коррелирован с целевым, чем остальные, причем, для региона `geo_1` коэффициент корреляция составляет ровно 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем дубликаты в признаке id\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i] = df_list[i].drop_duplicates(subset='id', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем строки, соотв. нулевому значению в признаке product\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list[i] = df_list[i][df_list[i]['product'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Проверка\n",
    "\n",
    "for item in df_list:\n",
    "    print(len(item[item['product'] == 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и проверка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним признаки и целевой признак (далее ц.п.) в отдельных переменных\n",
    "# Введём обозначения: X - список признаков по каждому региону, y - список ц.п. по каждому региону\n",
    "# Признак id уберём из рассмотрения (по всем регионам)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    X.append(df_list[i].drop(columns=['id', 'product'])) # извлекаем признаки\n",
    "    y.append(df_list[i]['product']) # извлекаем целевой признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные по каждому региону на обучающую и валидационную выборки в соотношении 75:25\n",
    "\n",
    "X0_train, X0_valid, y0_train, y0_valid = train_test_split(X[0], y[0], test_size=0.25, shuffle=True, random_state=STATE)\n",
    "X1_train, X1_valid, y1_train, y1_valid = train_test_split(X[1], y[1], test_size=0.25, shuffle=True, random_state=STATE)\n",
    "X2_train, X2_valid, y2_train, y2_valid = train_test_split(X[2], y[2], test_size=0.25, shuffle=True, random_state=STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74991, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24998, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74991,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(24998,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Проверка (для одного региона)\n",
    "\n",
    "display(X0_train.shape, X0_valid.shape)\n",
    "print('-' * 50)\n",
    "display(y0_train.shape, y0_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем признаки методом стандартизации\n",
    "\n",
    "X0_train, X0_valid = scaler_features(X0_train, X0_valid)\n",
    "X1_train, X1_valid = scaler_features(X1_train, X1_valid)\n",
    "X2_train, X2_valid = scaler_features(X2_train, X2_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модели линейной регрессии по каждому региону:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0, y0_pred, score_0 = lr_model(X0_train, X0_valid, y0_train, y0_valid)\n",
    "model_1, y1_pred, score_1 = lr_model(X1_train, X1_valid, y1_train, y1_valid)\n",
    "model_2, y2_pred, score_2 = lr_model(X2_train, X2_valid, y2_train, y2_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки модели на адекватность в каждом случае сравним с базовой моделью. В качестве базовой модели рассмотрим `DummyRegressor`, со стратегией `constant` (исп. среднее значение):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_score_0 = dr_model(X0_train, X0_valid, y0_train, y0_valid, y0_pred.mean())\n",
    "dr_score_1 = dr_model(X1_train, X1_valid, y1_train, y1_valid, y1_pred.mean())\n",
    "dr_score_2 = dr_model(X2_train, X2_valid, y2_train, y2_valid, y0_pred.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE for LinearReg</th>\n",
       "      <th>Average stock</th>\n",
       "      <th>RMSE for DummyReg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>geo_0</th>\n",
       "      <td>37.729</td>\n",
       "      <td>92.610</td>\n",
       "      <td>44.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_1</th>\n",
       "      <td>0.892</td>\n",
       "      <td>74.620</td>\n",
       "      <td>42.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_2</th>\n",
       "      <td>40.326</td>\n",
       "      <td>95.052</td>\n",
       "      <td>45.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RMSE for LinearReg  Average stock  RMSE for DummyReg\n",
       "geo_0              37.729         92.610             44.325\n",
       "geo_1               0.892         74.620             42.867\n",
       "geo_2              40.326         95.052             45.084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для вывода результатов\n",
    "\n",
    "result_evaluation_dict = {\n",
    "        'RMSE for LinearReg': [score_0.round(3), score_1.round(3), score_2.round(3)],\n",
    "        'Average stock': [y0_pred.mean().round(3), y1_pred.mean().round(3), y2_pred.mean().round(3)], \n",
    "        'RMSE for DummyReg': [dr_score_0.round(3), dr_score_1.round(3), dr_score_2.round(3)]\n",
    "}\n",
    "\n",
    "result_evaluation = pd.DataFrame(result_evaluation_dict, index=['geo_0', 'geo_1', 'geo_2'])\n",
    "display(result_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "\n",
    "Значение метрики модели линейной регрессии для региона `geo_1` существенно меньше по сравнению с остальными регионами, около 0.9 тыс.барр., что выглядит правдоподобно, учитывая очень сильную корреляцию по данному региону целевого признака с признаком `f2`.\n",
    "Также видно, что RMSE моделей линейной регрессии ниже, чем у констаных моделей, что свидетельствует об их адекватности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка к расчёту прибыли"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем достаточный объём сырья для безубыточной разработки новой скважины. Сравним полученный объём сырья со средним запасом в каждом регионе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Достаточный объём сырья для безубыточной разработки новой скважины составляет 111.111 тыс. баррелей\n"
     ]
    }
   ],
   "source": [
    "min_product_volume = BUDGET / NUM_WELLS / UNIT_INCOME\n",
    "print('Достаточный объём сырья для безубыточной разработки новой скважины \\\n",
    "составляет {} тыс. баррелей'.format(round(min_product_volume, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили, что по всем регионам средний запас предсказанного сырья ниже необходимого уровня для безубыточной разработки. Можно сделать вывод, что разработка любого из рассматриваемых регионов случайными 200 скважинами принесёт убытки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее напишем функцию расчёта прибыли по выбранным скважинам и предсказаниям модели. На вход она принимает датафрейм (из двух столбцов, значений ц.п. на валидационной выборке и предсказаний) и кол-во скважин для разработки, возвращает значение прибыли, подсчитанное для скважин с максимальными значениями предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция расчёта прибыли\n",
    "\n",
    "def income(df, count):\n",
    "    \n",
    "    top_pred = df.sort_values(by='predictions', ascending=False)\n",
    "    selected = top_pred['target'][:count]\n",
    "    \n",
    "    return UNIT_INCOME * selected.sum() - BUDGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчёт прибыли и рисков "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для определения распределения прибыли напишем функцию применения техники `Bootstrap` с 1000 выборками. На основе полученных данных рассчитаем среднюю прибыль, 95%-й доверительный интервал и риск убытков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция применения техники Bootstrap\n",
    "\n",
    "def bootstrap_income(target, predictions):\n",
    "    \n",
    "    state = np.random.RandomState(STATE)\n",
    "    \n",
    "    target = target.reset_index(drop=True)\n",
    "    predictions = pd.Series(predictions)\n",
    "    \n",
    "    df = pd.concat([target, predictions], axis=1)\n",
    "    df.columns = ['target', 'predictions']\n",
    "    \n",
    "    values_income = []\n",
    "    \n",
    "    for _ in range(N_SAMP):\n",
    "        df_sub = df.sample(n=N, replace=True, random_state=state)\n",
    "        values_income.append(income(df_sub, NUM_WELLS))\n",
    "        \n",
    "    values_income = pd.Series(values_income)\n",
    "    \n",
    "    mean_income = values_income.mean()\n",
    "    confidence_interval = [round(values_income.quantile(0.025) / 1000000, 1), \n",
    "                           round(values_income.quantile(0.975) / 1000000, 1)]\n",
    "    risk_loss = values_income[values_income < 0].count() / values_income.shape[0] * 100\n",
    "    \n",
    "    return mean_income, confidence_interval, risk_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_income_0, confidence_interval_0, risk_loss_0 = bootstrap_income(y0_valid, y0_pred)\n",
    "mean_income_1, confidence_interval_1, risk_loss_1 = bootstrap_income(y1_valid, y1_pred)\n",
    "mean_income_2, confidence_interval_2, risk_loss_2 = bootstrap_income(y2_valid, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average of income, mln. rub.</th>\n",
       "      <th>Interval</th>\n",
       "      <th>Risk of loss, %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>geo_0</th>\n",
       "      <td>418.0</td>\n",
       "      <td>[-141.5, 932.9]</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_1</th>\n",
       "      <td>678.6</td>\n",
       "      <td>[277.8, 1094.1]</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_2</th>\n",
       "      <td>344.5</td>\n",
       "      <td>[-165.0, 873.3]</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average of income, mln. rub.         Interval  Risk of loss, %\n",
       "geo_0                         418.0  [-141.5, 932.9]              7.0\n",
       "geo_1                         678.6  [277.8, 1094.1]              0.1\n",
       "geo_2                         344.5  [-165.0, 873.3]             10.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Для вывода результатов\n",
    "\n",
    "income_evaluation_dict = {\n",
    "        'Average of income, mln. rub.': [round(mean_income_0/1000000, 1), round(mean_income_1/1000000, 1), \n",
    "                                         round(mean_income_2/1000000, 1)],\n",
    "        'Interval': [confidence_interval_0, confidence_interval_1, confidence_interval_2], \n",
    "        'Risk of loss, %': [risk_loss_0, risk_loss_1, risk_loss_2]\n",
    "}\n",
    "\n",
    "income_evaluation = pd.DataFrame(income_evaluation_dict, index=['geo_0', 'geo_1', 'geo_2'])\n",
    "display(income_evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод:\n",
    "\n",
    "Получены данные по рискам убытков в трёх регионах, из которых видно, что на уровне меньше, чем 2.5%, находится только регион `geo_1`. Для этого же региона получена максимальная средняя прибыль. Данный регион может быть рекомендован для разработки месторождения."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 483,
    "start_time": "2023-05-03T17:16:09.851Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.336Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.337Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.338Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.339Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.341Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.342Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.360Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.361Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.362Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.363Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.364Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.365Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.365Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.366Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.368Z"
   },
   {
    "duration": 1,
    "start_time": "2023-05-03T17:16:10.368Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.370Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.370Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.372Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.373Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.374Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.374Z"
   },
   {
    "duration": 0,
    "start_time": "2023-05-03T17:16:10.375Z"
   },
   {
    "duration": 4252,
    "start_time": "2023-05-03T17:16:53.416Z"
   },
   {
    "duration": 2186,
    "start_time": "2023-05-03T17:17:03.805Z"
   },
   {
    "duration": 2364,
    "start_time": "2023-05-03T17:17:12.705Z"
   },
   {
    "duration": 2267,
    "start_time": "2023-05-03T17:17:15.072Z"
   },
   {
    "duration": 3,
    "start_time": "2023-05-03T17:17:17.341Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-03T17:17:17.346Z"
   },
   {
    "duration": 13,
    "start_time": "2023-05-03T17:17:17.361Z"
   },
   {
    "duration": 7,
    "start_time": "2023-05-03T17:17:17.376Z"
   },
   {
    "duration": 6,
    "start_time": "2023-05-03T17:17:17.385Z"
   },
   {
    "duration": 1255,
    "start_time": "2023-05-03T17:17:17.393Z"
   },
   {
    "duration": 13212,
    "start_time": "2023-05-03T17:17:18.650Z"
   },
   {
    "duration": 64,
    "start_time": "2023-05-03T17:17:31.865Z"
   },
   {
    "duration": 29,
    "start_time": "2023-05-03T17:17:31.931Z"
   },
   {
    "duration": 20,
    "start_time": "2023-05-03T17:17:31.962Z"
   },
   {
    "duration": 41,
    "start_time": "2023-05-03T17:17:31.983Z"
   },
   {
    "duration": 54,
    "start_time": "2023-05-03T17:17:32.025Z"
   },
   {
    "duration": 9,
    "start_time": "2023-05-03T17:17:32.082Z"
   },
   {
    "duration": 41,
    "start_time": "2023-05-03T17:17:32.092Z"
   },
   {
    "duration": 2,
    "start_time": "2023-05-03T17:17:32.135Z"
   },
   {
    "duration": 125,
    "start_time": "2023-05-03T17:17:32.138Z"
   },
   {
    "duration": 99,
    "start_time": "2023-05-03T17:17:32.266Z"
   },
   {
    "duration": 103,
    "start_time": "2023-05-03T17:17:32.369Z"
   },
   {
    "duration": 4,
    "start_time": "2023-05-03T17:17:32.474Z"
   },
   {
    "duration": 9,
    "start_time": "2023-05-03T17:17:32.480Z"
   },
   {
    "duration": 8,
    "start_time": "2023-05-03T17:17:32.490Z"
   },
   {
    "duration": 2276,
    "start_time": "2023-05-03T17:17:32.500Z"
   },
   {
    "duration": 10,
    "start_time": "2023-05-03T17:17:34.778Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
